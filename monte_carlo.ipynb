{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo System for simple 2x2 DiFnDif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATE\n",
    "\n",
    "$ Y_{it} = \\beta_0 + \\beta_1 \\text{Post}_t + \\beta_2 \\text{Treatment}_i + \\beta_3 (\\text{Post}_t \\times \\text{Treatment}_i) + \\sum_{k=1}^{K} \\beta_{k+3} (\\text{X}_i = k \\times \\text{Treatment}_i) + \\epsilon_{it} $\n",
    "\n",
    "Where:\n",
    "- $ Y_{it} $ represents the outcome variable (e.g., wages) for individual $ i $ at time $ t $.\n",
    "- $ \\text{Post}_t $ is a binary variable indicating whether the observation is from the post-treatment period.\n",
    "- $ \\text{Treatment}_i $ is a binary variable indicating whether individual $ i $ is in the treatment group.\n",
    "- $ \\text{X}_i $ is a categorical variable representing a conditioning variable (e.g., education level) for individual $ i $.\n",
    "- $ K $ is the total number of levels of the conditioning variable.\n",
    "- $ \\beta_{k+3} $ represents the coefficient for the interaction between the conditioning variable level $ k $ and the treatment indicator.\n",
    "- $ \\epsilon_{it} $ is the error term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Estimated Treatment Effect ($ \\beta $)**:\n",
    "   The treatment effect ($ \\beta $) is the coefficient associated with the interaction term between the treatment indicator and the post-treatment period indicator. Mathematically, it is given by:\n",
    "\n",
    "   $ \\beta = \\text{Coefficient of } (\\text{Post} \\times \\text{Treatment}) $\n",
    "\n",
    "2. **Standard Error ($ SE $)**:\n",
    "   The standard error ($ SE $) of the treatment effect estimates how much the estimated treatment effect varies across different samples. It can be calculated as the square root of the variance of the coefficient estimate. \n",
    "\n",
    "3. **t-statistic ($ t $)**:\n",
    "   The t-statistic ($ t $) is a measure of the signal-to-noise ratio in the estimated treatment effect. It is calculated by dividing the estimated treatment effect by its standard error. Mathematically, it can be expressed as:\n",
    "\n",
    "   $ t = \\frac{\\beta}{SE} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data generating process fertig machen mit richtiger verteilung\n",
    "- monte carlo machen\n",
    "- simulationsergebnisse und true values vergleichen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo for homogenous Treatment effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the coefficients (betas)\n",
    "true_beta_A = 2\n",
    "true_beta_B = 3\n",
    "true_beta_C = 6\n",
    "\n",
    "# Set the number of simulations\n",
    "num_simulations = 1000\n",
    "\n",
    "# Initialize lists to store estimated coefficients\n",
    "estimated_beta_A_list = []\n",
    "estimated_beta_B_list = []\n",
    "estimated_beta_C_list = []\n",
    "\n",
    "# Perform the simulations\n",
    "for _ in range(num_simulations):\n",
    "    # Generate random binary variables A, B, and C\n",
    "    A = np.random.randint(0, 2, size=num_simulations)\n",
    "    B = np.random.randint(0, 2, size=num_simulations)\n",
    "    C = A * B  # Interaction term of A and B\n",
    "\n",
    "    # Generate random control variables\n",
    "    control_1 = np.random.normal(0, 1, size=num_simulations)\n",
    "    control_2 = np.random.normal(0, 1, size=num_simulations)\n",
    "\n",
    "    mean_error = 0  # Mean of the error term\n",
    "    std_error = 10  # Standard deviation of the error term\n",
    "    error = np.random.normal(mean_error, std_error, size=num_simulations)\n",
    "\n",
    "    # Generate normally distributed outcome variable (wage)\n",
    "    mean_wage = 50  # Mean wage\n",
    "    std_wage = 10  # Standard deviation of wage\n",
    "    wage = (\n",
    "        mean_wage\n",
    "        + true_beta_A * A\n",
    "        + true_beta_B * B\n",
    "        + true_beta_C * C\n",
    "        + control_1\n",
    "        + control_2\n",
    "        + error\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for the variables\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"A\": A,\n",
    "            \"B\": B,\n",
    "            \"C\": C,\n",
    "            \"Control_1\": control_1,\n",
    "            \"Control_2\": control_2,\n",
    "            \"Wage\": wage,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create the model\n",
    "    X = sm.add_constant(data[[\"A\", \"B\", \"C\", \"Control_1\", \"Control_2\"]])\n",
    "    y = data[\"Wage\"]\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Extract the estimated coefficients and append to the lists\n",
    "    estimated_beta_A_list.append(results.params[\"A\"])\n",
    "    estimated_beta_B_list.append(results.params[\"B\"])\n",
    "    estimated_beta_C_list.append(results.params[\"C\"])\n",
    "\n",
    "# Calculate the average estimated coefficients\n",
    "average_estimated_beta_A = np.mean(estimated_beta_A_list)\n",
    "average_estimated_beta_B = np.mean(estimated_beta_B_list)\n",
    "average_estimated_beta_C = np.mean(estimated_beta_C_list)\n",
    "\n",
    "# Print the true coefficients and the average estimated coefficients\n",
    "print(\"True Coefficients:\")\n",
    "print(\"Beta_A:\", true_beta_A)\n",
    "print(\"Beta_B:\", true_beta_B)\n",
    "print(\"Beta_C:\", true_beta_C)\n",
    "print(\"\\nAverage Estimated Coefficients:\")\n",
    "print(\"Beta_A (Average Estimated):\", average_estimated_beta_A)\n",
    "print(\"Beta_B (Average Estimated):\", average_estimated_beta_B)\n",
    "print(\"Beta_C (Average Estimated):\", average_estimated_beta_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Combine the estimated coefficients into a single DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": estimated_beta_A_list,\n",
    "        \"B\": estimated_beta_B_list,\n",
    "        \"C\": estimated_beta_C_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Plot kernel density estimates for each coefficient\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df, fill=True, palette=\"Set1\")\n",
    "plt.axvline(x=true_beta_A, color=\"red\", linestyle=\"--\", label=\"True Beta A\")\n",
    "plt.axvline(x=true_beta_B, color=\"blue\", linestyle=\"--\", label=\"True Beta B\")\n",
    "plt.axvline(x=true_beta_C, color=\"green\", linestyle=\"--\", label=\"True Beta C\")\n",
    "plt.title(\"Kernel Density Plot of Estimated Coefficients\")\n",
    "plt.xlabel(\"Estimated Coefficient Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo for hetergenous Treatment effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the true coefficients\n",
    "true_beta_A = 2\n",
    "true_beta_B = 3\n",
    "true_beta_C = 6\n",
    "true_beta_A_X = -20  # Interaction effect of A and covariate X\n",
    "true_beta_B_X = 40  # Interaction effect of B and covariate X\n",
    "\n",
    "# Set the number of simulations\n",
    "num_simulations = 1000\n",
    "\n",
    "# Initialize lists to store estimated coefficients for both models\n",
    "estimated_beta_homogeneous_list = []\n",
    "estimated_beta_heterogeneous_list = []\n",
    "\n",
    "# Perform the simulations\n",
    "for _ in range(num_simulations):\n",
    "    # Generate random binary variables A, B, and C\n",
    "    A = np.random.randint(0, 2, size=num_simulations)\n",
    "    B = np.random.randint(0, 2, size=num_simulations)\n",
    "    C = np.random.randint(0, 2, size=num_simulations)\n",
    "\n",
    "    # Generate random covariate X\n",
    "    X = np.random.normal(0, 5, size=num_simulations)\n",
    "\n",
    "    # Generate random control variables\n",
    "    control_1 = np.random.normal(0, 1, size=num_simulations)\n",
    "    control_2 = np.random.normal(0, 1, size=num_simulations)\n",
    "\n",
    "    mean_error = 0  # Mean of the error term\n",
    "    std_error = 10  # Standard deviation of the error term\n",
    "    error = np.random.normal(mean_error, std_error, size=num_simulations)\n",
    "\n",
    "    # Generate normally distributed outcome variable (wage)\n",
    "    mean_wage = 50  # Mean wage\n",
    "    std_wage = 10  # Standard deviation of wage\n",
    "    wage = (\n",
    "        mean_wage\n",
    "        + true_beta_A * A\n",
    "        + true_beta_B * B\n",
    "        + true_beta_C * C\n",
    "        + true_beta_A_X * A * X\n",
    "        + true_beta_B_X * B * X\n",
    "        + control_1\n",
    "        + control_2\n",
    "        + error\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for the variables\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"A\": A,\n",
    "            \"B\": B,\n",
    "            \"C\": C,\n",
    "            \"X\": X,\n",
    "            \"Control_1\": control_1,\n",
    "            \"Control_2\": control_2,\n",
    "            \"Wage\": wage,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create the homogenous treatment effect model\n",
    "    X_homogeneous = sm.add_constant(\n",
    "        data[[\"A\", \"B\", \"C\", \"X\", \"Control_1\", \"Control_2\"]],\n",
    "    )\n",
    "    y_homogeneous = data[\"Wage\"]\n",
    "    model_homogeneous = sm.OLS(y_homogeneous, X_homogeneous)\n",
    "    results_homogeneous = model_homogeneous.fit()\n",
    "    estimated_beta_homogeneous_list.append(results_homogeneous.params[\"C\"])\n",
    "\n",
    "    # Create the heterogeneous treatment effect model\n",
    "    data[\"A_X\"] = data[\"A\"] * data[\"X\"]\n",
    "    data[\"B_X\"] = data[\"B\"] * data[\"X\"]\n",
    "    X_heterogeneous = sm.add_constant(\n",
    "        data[[\"A\", \"B\", \"C\", \"X\", \"A_X\", \"B_X\", \"Control_1\", \"Control_2\"]],\n",
    "    )\n",
    "    y_heterogeneous = data[\"Wage\"]\n",
    "    model_heterogeneous = sm.OLS(y_heterogeneous, X_heterogeneous)\n",
    "    results_heterogeneous = model_heterogeneous.fit()\n",
    "    estimated_beta_heterogeneous_list.append(results_heterogeneous.params[\"C\"])\n",
    "\n",
    "# Calculate the average estimated coefficients for both models\n",
    "average_estimated_beta_homogeneous = np.mean(estimated_beta_homogeneous_list)\n",
    "average_estimated_beta_heterogeneous = np.mean(estimated_beta_heterogeneous_list)\n",
    "\n",
    "# Print the true coefficient and the average estimated coefficients for both models\n",
    "print(\"True Coefficient (Heterogeneous Treatment Effect):\", true_beta_C)\n",
    "print(\n",
    "    \"Average Estimated Coefficient (Homogeneous Treatment Effect Model):\",\n",
    "    average_estimated_beta_homogeneous,\n",
    ")\n",
    "print(\n",
    "    \"Average Estimated Coefficient (Heterogeneous Treatment Effect Model):\",\n",
    "    average_estimated_beta_heterogeneous,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors for coefficients\n",
    "homogeneous_color = \"blue\"\n",
    "heterogeneous_color = \"orange\"\n",
    "\n",
    "# Combine the estimated coefficients into DataFrames\n",
    "homogeneous_df = pd.DataFrame(\n",
    "    {\"Coefficient\": estimated_beta_homogeneous_list, \"Model\": \"Homogeneous\"},\n",
    ")\n",
    "heterogeneous_df = pd.DataFrame(\n",
    "    {\"Coefficient\": estimated_beta_heterogeneous_list, \"Model\": \"Heterogeneous\"},\n",
    ")\n",
    "\n",
    "# Concatenate DataFrames\n",
    "df = pd.concat([homogeneous_df, heterogeneous_df])\n",
    "\n",
    "# Plot kernel density estimates for each coefficient\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    data=df,\n",
    "    x=\"Coefficient\",\n",
    "    hue=\"Model\",\n",
    "    fill=True,\n",
    "    palette={\"Homogeneous\": homogeneous_color, \"Heterogeneous\": heterogeneous_color},\n",
    ")\n",
    "plt.axvline(x=true_beta_C, color=\"green\", linestyle=\"--\", label=\"True Beta C\")\n",
    "plt.title(\"Kernel Density Plot of Estimated Coefficients\")\n",
    "plt.xlabel(\"Estimated Coefficient Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# econML library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION = \"python\"  # add this\n",
    "from causal_nets import causal_net_estimate\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(3)\n",
    "\n",
    "# Generating the fake data\n",
    "N = 10000\n",
    "X = np.random.uniform(low=0, high=1, size=[N, 10])\n",
    "mu0_real = (\n",
    "    1.5\n",
    "    + 0.012 * X[:, 3]\n",
    "    - 0.75 * X[:, 5] * X[:, 7]\n",
    "    - 0.9 * X[:, 4]\n",
    "    - np.mean(X, axis=1)\n",
    ")\n",
    "tau_real = X[:, 2] + 0.04 * X[:, 9] - 0.35 * np.log(X[:, 3])\n",
    "prob_of_T = 0.5\n",
    "T = np.random.binomial(size=N, n=1, p=prob_of_T)\n",
    "normal_errors = np.random.normal(\n",
    "    size=[\n",
    "        N,\n",
    "    ],\n",
    "    loc=0.0,\n",
    "    scale=1.0,\n",
    ")\n",
    "Y = mu0_real + tau_real * T + normal_errors\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "bins = np.linspace(\n",
    "    min(float(min(tau_pred)), float(min(tau_real))),\n",
    "    max(float(max(tau_pred)), float(max(tau_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    tau_real,\n",
    "    label=r\"$\\tau~_{ real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bins = np.linspace(\n",
    "    min(float(min(mu0_pred)), float(min(mu0_real))),\n",
    "    max(float(max(mu0_pred)), float(max(mu0_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    mu0_real,\n",
    "    label=r\"$\\mu_{0~real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip install tensoflow==2.10.0\n",
    "- pip install protobuf==3.11.3\n",
    "- pip uninstall protobuf\n",
    "- conda install protobuf\n",
    "- pip install \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION = \"python\"  # add this\n",
    "from causal_nets import causal_net_estimate\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(3)\n",
    "\n",
    "# Generating the fake data\n",
    "N = 10000\n",
    "X = np.random.uniform(low=0, high=1, size=[N, 10])\n",
    "mu0_real = (\n",
    "    1.5\n",
    "    + 0.012 * X[:, 3]\n",
    "    - 0.75 * X[:, 5] * X[:, 7]\n",
    "    - 0.9 * X[:, 4]\n",
    "    - np.mean(X, axis=1)\n",
    ")\n",
    "tau_real = X[:, 2] + 0.04 * X[:, 9] - 0.35 * np.log(X[:, 3])\n",
    "prob_of_T = 0.5\n",
    "T = np.random.binomial(size=N, n=1, p=prob_of_T)\n",
    "normal_errors = np.random.normal(\n",
    "    size=[\n",
    "        N,\n",
    "    ],\n",
    "    loc=0.0,\n",
    "    scale=1.0,\n",
    ")\n",
    "Y = mu0_real + tau_real * T + normal_errors\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "bins = np.linspace(\n",
    "    min(float(min(tau_pred)), float(min(tau_real))),\n",
    "    max(float(max(tau_pred)), float(max(tau_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    tau_real,\n",
    "    label=r\"$\\tau~_{ real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bins = np.linspace(\n",
    "    min(float(min(mu0_pred)), float(min(mu0_real))),\n",
    "    max(float(max(mu0_pred)), float(max(mu0_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    mu0_real,\n",
    "    label=r\"$\\mu_{0~real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
