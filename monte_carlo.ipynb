{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo System for simple 2x2 DiFnDif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATE\n",
    "\n",
    "$ Y_{it} = \\beta_0 + \\beta_1 \\text{Post}_t + \\beta_2 \\text{Treatment}_i + \\beta_3 (\\text{Post}_t \\times \\text{Treatment}_i) + \\sum_{k=1}^{K} \\beta_{k+3} (\\text{X}_i = k \\times \\text{Treatment}_i) + \\epsilon_{it} $\n",
    "\n",
    "Where:\n",
    "- $ Y_{it} $ represents the outcome variable (e.g., wages) for individual $ i $ at time $ t $.\n",
    "- $ \\text{Post}_t $ is a binary variable indicating whether the observation is from the post-treatment period.\n",
    "- $ \\text{Treatment}_i $ is a binary variable indicating whether individual $ i $ is in the treatment group.\n",
    "- $ \\text{X}_i $ is a categorical variable representing a conditioning variable (e.g., education level) for individual $ i $.\n",
    "- $ K $ is the total number of levels of the conditioning variable.\n",
    "- $ \\beta_{k+3} $ represents the coefficient for the interaction between the conditioning variable level $ k $ and the treatment indicator.\n",
    "- $ \\epsilon_{it} $ is the error term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Estimated Treatment Effect ($ \\beta $)**:\n",
    "   The treatment effect ($ \\beta $) is the coefficient associated with the interaction term between the treatment indicator and the post-treatment period indicator. Mathematically, it is given by:\n",
    "\n",
    "   $ \\beta = \\text{Coefficient of } (\\text{Post} \\times \\text{Treatment}) $\n",
    "\n",
    "2. **Standard Error ($ SE $)**:\n",
    "   The standard error ($ SE $) of the treatment effect estimates how much the estimated treatment effect varies across different samples. It can be calculated as the square root of the variance of the coefficient estimate. \n",
    "\n",
    "3. **t-statistic ($ t $)**:\n",
    "   The t-statistic ($ t $) is a measure of the signal-to-noise ratio in the estimated treatment effect. It is calculated by dividing the estimated treatment effect by its standard error. Mathematically, it can be expressed as:\n",
    "\n",
    "   $ t = \\frac{\\beta}{SE} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data generating process fertig machen mit richtiger verteilung\n",
    "- monte carlo machen\n",
    "- simulationsergebnisse und true values vergleichen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo for homogenous Treatment effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the coefficients (betas)\n",
    "true_beta_A = 2\n",
    "true_beta_B = 3\n",
    "true_beta_C = 6\n",
    "\n",
    "# Set the number of simulations\n",
    "num_simulations = 1000\n",
    "\n",
    "# Initialize lists to store estimated coefficients\n",
    "estimated_beta_A_list = []\n",
    "estimated_beta_B_list = []\n",
    "estimated_beta_C_list = []\n",
    "\n",
    "# Perform the simulations\n",
    "for _ in range(num_simulations):\n",
    "    # Generate random binary variables A, B, and C\n",
    "    A = np.random.randint(0, 2, size=num_simulations)\n",
    "    B = np.random.randint(0, 2, size=num_simulations)\n",
    "    C = A * B  # Interaction term of A and B\n",
    "\n",
    "    # Generate random control variables\n",
    "    control_1 = np.random.normal(0, 1, size=num_simulations)\n",
    "    control_2 = np.random.normal(0, 1, size=num_simulations)\n",
    "\n",
    "    mean_error = 0  # Mean of the error term\n",
    "    std_error = 10  # Standard deviation of the error term\n",
    "    error = np.random.normal(mean_error, std_error, size=num_simulations)\n",
    "\n",
    "    # Generate normally distributed outcome variable (wage)\n",
    "    mean_wage = 50  # Mean wage\n",
    "    std_wage = 10  # Standard deviation of wage\n",
    "    wage = (\n",
    "        mean_wage\n",
    "        + true_beta_A * A\n",
    "        + true_beta_B * B\n",
    "        + true_beta_C * C\n",
    "        + control_1\n",
    "        + control_2\n",
    "        + error\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for the variables\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"A\": A,\n",
    "            \"B\": B,\n",
    "            \"C\": C,\n",
    "            \"Control_1\": control_1,\n",
    "            \"Control_2\": control_2,\n",
    "            \"Wage\": wage,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create the model\n",
    "    X = sm.add_constant(data[[\"A\", \"B\", \"C\", \"Control_1\", \"Control_2\"]])\n",
    "    y = data[\"Wage\"]\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Extract the estimated coefficients and append to the lists\n",
    "    estimated_beta_A_list.append(results.params[\"A\"])\n",
    "    estimated_beta_B_list.append(results.params[\"B\"])\n",
    "    estimated_beta_C_list.append(results.params[\"C\"])\n",
    "\n",
    "# Calculate the average estimated coefficients\n",
    "average_estimated_beta_A = np.mean(estimated_beta_A_list)\n",
    "average_estimated_beta_B = np.mean(estimated_beta_B_list)\n",
    "average_estimated_beta_C = np.mean(estimated_beta_C_list)\n",
    "\n",
    "# Print the true coefficients and the average estimated coefficients\n",
    "print(\"True Coefficients:\")\n",
    "print(\"Beta_A:\", true_beta_A)\n",
    "print(\"Beta_B:\", true_beta_B)\n",
    "print(\"Beta_C:\", true_beta_C)\n",
    "print(\"\\nAverage Estimated Coefficients:\")\n",
    "print(\"Beta_A (Average Estimated):\", average_estimated_beta_A)\n",
    "print(\"Beta_B (Average Estimated):\", average_estimated_beta_B)\n",
    "print(\"Beta_C (Average Estimated):\", average_estimated_beta_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Combine the estimated coefficients into a single DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": estimated_beta_A_list,\n",
    "        \"B\": estimated_beta_B_list,\n",
    "        \"C\": estimated_beta_C_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Plot kernel density estimates for each coefficient\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df, fill=True, palette=\"Set1\")\n",
    "plt.axvline(x=true_beta_A, color=\"red\", linestyle=\"--\", label=\"True Beta A\")\n",
    "plt.axvline(x=true_beta_B, color=\"blue\", linestyle=\"--\", label=\"True Beta B\")\n",
    "plt.axvline(x=true_beta_C, color=\"green\", linestyle=\"--\", label=\"True Beta C\")\n",
    "plt.title(\"Kernel Density Plot of Estimated Coefficients\")\n",
    "plt.xlabel(\"Estimated Coefficient Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo for hetergenous Treatment effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the true coefficients\n",
    "true_beta_A = 2\n",
    "true_beta_B = 3\n",
    "true_beta_C = 6\n",
    "true_beta_A_X = -20  # Interaction effect of A and covariate X\n",
    "true_beta_B_X = 40  # Interaction effect of B and covariate X\n",
    "\n",
    "# Set the number of simulations\n",
    "num_simulations = 1000\n",
    "\n",
    "# Initialize lists to store estimated coefficients for both models\n",
    "estimated_beta_homogeneous_list = []\n",
    "estimated_beta_heterogeneous_list = []\n",
    "\n",
    "# Perform the simulations\n",
    "for _ in range(num_simulations):\n",
    "    # Generate random binary variables A, B, and C\n",
    "    A = np.random.randint(0, 2, size=num_simulations)\n",
    "    B = np.random.randint(0, 2, size=num_simulations)\n",
    "    C = np.random.randint(0, 2, size=num_simulations)\n",
    "\n",
    "    # Generate random covariate X\n",
    "    X = np.random.normal(0, 5, size=num_simulations)\n",
    "\n",
    "    # Generate random control variables\n",
    "    control_1 = np.random.normal(0, 1, size=num_simulations)\n",
    "    control_2 = np.random.normal(0, 1, size=num_simulations)\n",
    "\n",
    "    mean_error = 0  # Mean of the error term\n",
    "    std_error = 10  # Standard deviation of the error term\n",
    "    error = np.random.normal(mean_error, std_error, size=num_simulations)\n",
    "\n",
    "    # Generate normally distributed outcome variable (wage)\n",
    "    mean_wage = 50  # Mean wage\n",
    "    std_wage = 10  # Standard deviation of wage\n",
    "    wage = (\n",
    "        mean_wage\n",
    "        + true_beta_A * A\n",
    "        + true_beta_B * B\n",
    "        + true_beta_C * C\n",
    "        + true_beta_A_X * A * X\n",
    "        + true_beta_B_X * B * X\n",
    "        + control_1\n",
    "        + control_2\n",
    "        + error\n",
    "    )\n",
    "\n",
    "    # Create a DataFrame for the variables\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"A\": A,\n",
    "            \"B\": B,\n",
    "            \"C\": C,\n",
    "            \"X\": X,\n",
    "            \"Control_1\": control_1,\n",
    "            \"Control_2\": control_2,\n",
    "            \"Wage\": wage,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create the homogenous treatment effect model\n",
    "    X_homogeneous = sm.add_constant(\n",
    "        data[[\"A\", \"B\", \"C\", \"X\", \"Control_1\", \"Control_2\"]],\n",
    "    )\n",
    "    y_homogeneous = data[\"Wage\"]\n",
    "    model_homogeneous = sm.OLS(y_homogeneous, X_homogeneous)\n",
    "    results_homogeneous = model_homogeneous.fit()\n",
    "    estimated_beta_homogeneous_list.append(results_homogeneous.params[\"C\"])\n",
    "\n",
    "    # Create the heterogeneous treatment effect model\n",
    "    data[\"A_X\"] = data[\"A\"] * data[\"X\"]\n",
    "    data[\"B_X\"] = data[\"B\"] * data[\"X\"]\n",
    "    X_heterogeneous = sm.add_constant(\n",
    "        data[[\"A\", \"B\", \"C\", \"X\", \"A_X\", \"B_X\", \"Control_1\", \"Control_2\"]],\n",
    "    )\n",
    "    y_heterogeneous = data[\"Wage\"]\n",
    "    model_heterogeneous = sm.OLS(y_heterogeneous, X_heterogeneous)\n",
    "    results_heterogeneous = model_heterogeneous.fit()\n",
    "    estimated_beta_heterogeneous_list.append(results_heterogeneous.params[\"C\"])\n",
    "\n",
    "# Calculate the average estimated coefficients for both models\n",
    "average_estimated_beta_homogeneous = np.mean(estimated_beta_homogeneous_list)\n",
    "average_estimated_beta_heterogeneous = np.mean(estimated_beta_heterogeneous_list)\n",
    "\n",
    "# Print the true coefficient and the average estimated coefficients for both models\n",
    "print(\"True Coefficient (Heterogeneous Treatment Effect):\", true_beta_C)\n",
    "print(\n",
    "    \"Average Estimated Coefficient (Homogeneous Treatment Effect Model):\",\n",
    "    average_estimated_beta_homogeneous,\n",
    ")\n",
    "print(\n",
    "    \"Average Estimated Coefficient (Heterogeneous Treatment Effect Model):\",\n",
    "    average_estimated_beta_heterogeneous,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define custom colors for coefficients\n",
    "homogeneous_color = \"blue\"\n",
    "heterogeneous_color = \"orange\"\n",
    "\n",
    "# Combine the estimated coefficients into DataFrames\n",
    "homogeneous_df = pd.DataFrame(\n",
    "    {\"Coefficient\": estimated_beta_homogeneous_list, \"Model\": \"Homogeneous\"},\n",
    ")\n",
    "heterogeneous_df = pd.DataFrame(\n",
    "    {\"Coefficient\": estimated_beta_heterogeneous_list, \"Model\": \"Heterogeneous\"},\n",
    ")\n",
    "\n",
    "# Concatenate DataFrames\n",
    "df = pd.concat([homogeneous_df, heterogeneous_df])\n",
    "\n",
    "# Plot kernel density estimates for each coefficient\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    data=df,\n",
    "    x=\"Coefficient\",\n",
    "    hue=\"Model\",\n",
    "    fill=True,\n",
    "    palette={\"Homogeneous\": homogeneous_color, \"Heterogeneous\": heterogeneous_color},\n",
    ")\n",
    "plt.axvline(x=true_beta_C, color=\"green\", linestyle=\"--\", label=\"True Beta C\")\n",
    "plt.title(\"Kernel Density Plot of Estimated Coefficients\")\n",
    "plt.xlabel(\"Estimated Coefficient Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION = \"python\"  # add this\n",
    "from causal_nets import causal_net_estimate\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(3)\n",
    "\n",
    "# Generating the fake data\n",
    "N = 10000\n",
    "X = np.random.uniform(low=0, high=1, size=[N, 10])\n",
    "mu0_real = (\n",
    "    1.5\n",
    "    + 0.012 * X[:, 3]\n",
    "    - 0.75 * X[:, 5] * X[:, 7]\n",
    "    - 0.9 * X[:, 4]\n",
    "    - np.mean(X, axis=1)\n",
    ")\n",
    "tau_real = X[:, 2] + 0.04 * X[:, 9] - 0.35 * np.log(X[:, 3])\n",
    "prob_of_T = 0.5\n",
    "T = np.random.binomial(size=N, n=1, p=prob_of_T)\n",
    "normal_errors = np.random.normal(\n",
    "    size=[\n",
    "        N,\n",
    "    ],\n",
    "    loc=0.0,\n",
    "    scale=1.0,\n",
    ")\n",
    "Y = mu0_real + tau_real * T + normal_errors\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "bins = np.linspace(\n",
    "    min(float(min(tau_pred)), float(min(tau_real))),\n",
    "    max(float(max(tau_pred)), float(max(tau_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    tau_real,\n",
    "    label=r\"$\\tau~_{ real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bins = np.linspace(\n",
    "    min(float(min(mu0_pred)), float(min(mu0_real))),\n",
    "    max(float(max(mu0_pred)), float(max(mu0_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    mu0_real,\n",
    "    label=r\"$\\mu_{0~real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip install tensoflow==2.10.0\n",
    "- pip install protobuf==3.11.3\n",
    "- pip uninstall protobuf\n",
    "- conda install protobuf\n",
    "- pip install \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference in Difference Deep Learning approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust the following function to DiD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATE\n",
    "\n",
    "$ Y_{it} = \\beta_0 + \\beta_1 \\text{Post}_t + \\beta_2 \\text{Treatment}_i + \\beta_3 (\\text{Post}_t \\times \\text{Treatment}_i) + \\sum_{k=1}^{K} \\beta_{k+3} (\\text{X}_i = k \\times \\text{Treatment}_i) + \\epsilon_{it} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION = \"python\"  # add this\n",
    "from causal_nets import causal_net_estimate\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(3)\n",
    "\n",
    "# Generating the fake data\n",
    "N = 10000\n",
    "X = np.random.uniform(low=0, high=1, size=[N, 10])\n",
    "mu0_real = (\n",
    "    1.5\n",
    "    + 0.012 * X[:, 3]\n",
    "    - 0.75 * X[:, 5] * X[:, 7]\n",
    "    - 0.9 * X[:, 4]\n",
    "    - np.mean(X, axis=1)\n",
    ")\n",
    "tau_real = X[:, 2] + 0.04 * X[:, 9] - 0.35 * np.log(X[:, 3])\n",
    "prob_of_T = 0.5\n",
    "T = np.random.binomial(size=N, n=1, p=prob_of_T)\n",
    "normal_errors = np.random.normal(\n",
    "    size=[\n",
    "        N,\n",
    "    ],\n",
    "    loc=0.0,\n",
    "    scale=1.0,\n",
    ")\n",
    "Y = mu0_real + tau_real * T + normal_errors\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "bins = np.linspace(\n",
    "    min(float(min(tau_pred)), float(min(tau_real))),\n",
    "    max(float(max(tau_pred)), float(max(tau_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    tau_real,\n",
    "    label=r\"$\\tau~_{ real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bins = np.linspace(\n",
    "    min(float(min(mu0_pred)), float(min(mu0_real))),\n",
    "    max(float(max(mu0_pred)), float(max(mu0_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    mu0_real,\n",
    "    label=r\"$\\mu_{0~real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference in Difference with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(3)\n",
    "\n",
    "# Generating the fake data\n",
    "N = 10000\n",
    "X = np.random.uniform(low=0, high=1, size=[N, 10])\n",
    "mu0_real = (\n",
    "    1.5\n",
    "    + 0.012 * X[:, 3]\n",
    "    - 0.75 * X[:, 5] * X[:, 7]\n",
    "    - 0.9 * X[:, 4]\n",
    "    - np.mean(X, axis=1)\n",
    ")\n",
    "tau_real = X[:, 2] + 0.04 * X[:, 9] - 0.35 * np.log(X[:, 3])\n",
    "prob_of_T = 0.5\n",
    "T = np.random.binomial(size=N, n=1, p=prob_of_T)\n",
    "normal_errors = np.random.normal(\n",
    "    size=[\n",
    "        N,\n",
    "    ],\n",
    "    loc=0.0,\n",
    "    scale=1.0,\n",
    ")\n",
    "Y = mu0_real + tau_real * T + normal_errors\n",
    "\n",
    "# Creating training and validation dataset\n",
    "(\n",
    "    X_train_before,\n",
    "    X_valid_before,\n",
    "    T_train_before,\n",
    "    T_valid_before,\n",
    "    Y_train_before,\n",
    "    Y_valid_before,\n",
    ") = train_test_split(\n",
    "    X[: N // 2],  # Split the data for before intervention period\n",
    "    T[: N // 2],\n",
    "    Y[: N // 2],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "(\n",
    "    X_train_after,\n",
    "    X_valid_after,\n",
    "    T_train_after,\n",
    "    T_valid_after,\n",
    "    Y_train_after,\n",
    "    Y_valid_after,\n",
    ") = train_test_split(\n",
    "    X[N // 2 :],  # Split the data for after intervention period\n",
    "    T[N // 2 :],\n",
    "    Y[N // 2 :],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_train_before, X_train_after))\n",
    "X_valid = np.concatenate((X_valid_before, X_valid_after))\n",
    "T_train = np.concatenate((T_train_before, T_train_after))\n",
    "T_valid = np.concatenate((T_valid_before, T_valid_after))\n",
    "Y_train = np.concatenate((Y_train_before, Y_train_after))\n",
    "Y_valid = np.concatenate((Y_valid_before, Y_valid_after))\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "bins = np.linspace(\n",
    "    min(float(min(tau_pred)), float(min(tau_real))),\n",
    "    max(float(max(tau_pred)), float(max(tau_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    tau_real,\n",
    "    label=r\"$\\tau~_{ real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bins = np.linspace(\n",
    "    min(float(min(mu0_pred)), float(min(mu0_real))),\n",
    "    max(float(max(mu0_pred)), float(max(mu0_real))),\n",
    "    15,\n",
    ")\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True, bins=bins)\n",
    "plt.hist(\n",
    "    mu0_real,\n",
    "    label=r\"$\\mu_{0~real}$\",\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2.5,\n",
    "    bins=bins,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_indices = np.where(T_train == 1)[0]  # Get indices where T_train == 1\n",
    "att = np.mean(psi_1[att_indices] - psi_0[att_indices])\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect on the treated (ATT)\n",
    "ci_lowerbound = att - norm.ppf(0.975) * np.std(\n",
    "    psi_1[att_indices] - psi_0[att_indices],\n",
    ") / np.sqrt(len(att_indices))\n",
    "ci_upperbound = att + norm.ppf(0.975) * np.std(\n",
    "    psi_1[att_indices] - psi_0[att_indices],\n",
    ") / np.sqrt(len(att_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Modell Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Smooth curve to show\n",
    "- show average treatment effect across repetitions (basically there should be one true value whre it revolves around and not multiple true ones generated each turn)\n",
    "- Note: Cate are ATE in 2x2 DifnDif\n",
    "- Note: We speak about ATT and not ATE\n",
    "- Adjust every model to the same DGP, adjust the DGP to highlight different problems and how the models deal with that\n",
    "- Note: beta is either a distribution or just zero (then it is linear)\n",
    "    - it would be interesting to show both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approach: same data generating process, different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to generate data for difference-in-differences (DiD) model\n",
    "\n",
    "\n",
    "def generate_data(num_simulations):\n",
    "    # Set the coefficients (betas)\n",
    "    true_beta_A = 2\n",
    "    true_beta_B = 3\n",
    "    true_beta_C = 6  # Update true_beta_C to be 6\n",
    "\n",
    "    # Initialize lists to store generated data\n",
    "    X = []\n",
    "    T = []\n",
    "    Y = []\n",
    "\n",
    "    # Perform the simulations\n",
    "    for _ in range(num_simulations):\n",
    "        # Generate random binary variables A (treatment) and B (control)\n",
    "        A = np.random.randint(0, 2)\n",
    "        B = 1 - A  # B is the control group\n",
    "\n",
    "        # Generate a time variable to represent before and after periods\n",
    "        time = np.random.randint(0, 2)\n",
    "\n",
    "        # Interaction term of treatment and time\n",
    "        C = A * time\n",
    "\n",
    "        # Generate random control variables\n",
    "        control_1 = np.random.normal(0, 1)\n",
    "        control_2 = np.random.normal(0, 1)\n",
    "\n",
    "        mean_error = 0  # Mean of the error term\n",
    "        std_error = 10  # Standard deviation of the error term\n",
    "        error = np.random.normal(mean_error, std_error)\n",
    "\n",
    "        # Generate normally distributed outcome variable (wage)\n",
    "        mean_wage = 50  # Mean wage\n",
    "        wage = (\n",
    "            mean_wage\n",
    "            + true_beta_A * A\n",
    "            + true_beta_B * B\n",
    "            + true_beta_C * C  # Treatment effect\n",
    "            + control_1\n",
    "            + control_2\n",
    "            + error\n",
    "        )\n",
    "\n",
    "        # Store the generated data\n",
    "        X.append([A, B, C, control_1, control_2])\n",
    "        T.append(time)\n",
    "        Y.append(wage)\n",
    "\n",
    "    return np.array(X), np.array(T), np.array(Y)\n",
    "\n",
    "\n",
    "# Generating the fake data\n",
    "X, T, Y = generate_data(10000)\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_C, color=\"r\", linestyle=\"--\", label=r\"$\\tau~_{ real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_A, color=\"r\", linestyle=\"--\", label=r\"$\\mu_{0~real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to generate data for difference-in-differences (DiD) model\n",
    "\n",
    "\n",
    "def generate_data(num_simulations, noise_std=10):\n",
    "    # Set the coefficients (betas)\n",
    "    true_beta_A = 2\n",
    "    true_beta_B = 3\n",
    "    true_beta_C = 6  # Update true_beta_C to be 6\n",
    "\n",
    "    # Initialize lists to store generated data\n",
    "    X = []\n",
    "    T = []\n",
    "    Y = []\n",
    "\n",
    "    # Perform the simulations\n",
    "    for _ in range(num_simulations):\n",
    "        # Generate random binary variables A (treatment) and B (control)\n",
    "        A = np.random.randint(0, 2)\n",
    "        B = 1 - A  # B is the control group\n",
    "\n",
    "        # Generate a time variable to represent before and after periods\n",
    "        time = np.random.randint(0, 2)\n",
    "\n",
    "        # Interaction term of treatment and time\n",
    "        C = A * time\n",
    "\n",
    "        # Generate random control variables\n",
    "        control_1 = np.random.normal(0, 1)\n",
    "        control_2 = np.random.normal(0, 1)\n",
    "\n",
    "        mean_error = 0  # Mean of the error term\n",
    "        std_error = noise_std  # Standard deviation of the error term\n",
    "        error = np.random.normal(mean_error, std_error)\n",
    "\n",
    "        # Generate normally distributed outcome variable (wage)\n",
    "        mean_wage = 50  # Mean wage\n",
    "        wage = (\n",
    "            mean_wage\n",
    "            + true_beta_A * A\n",
    "            + true_beta_B * B\n",
    "            + true_beta_C * C  # Treatment effect\n",
    "            + control_1\n",
    "            + control_2\n",
    "            + error\n",
    "        )\n",
    "\n",
    "        # Store the generated data\n",
    "        X.append([A, B, C, control_1, control_2])\n",
    "        T.append(time)\n",
    "        Y.append(wage)\n",
    "\n",
    "    return np.array(X), np.array(T), np.array(Y)\n",
    "\n",
    "\n",
    "# Generating the fake data with noise\n",
    "X, T, Y = generate_data(10000, noise_std=10)  # Adding noise with std=10\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_C, color=\"r\", linestyle=\"--\", label=r\"$\\tau~_{ real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_A, color=\"r\", linestyle=\"--\", label=r\"$\\mu_{0~real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to generate data for difference-in-differences (DiD) model\n",
    "\n",
    "\n",
    "def generate_data(num_simulations, noise_std=10, num_covariates=10):\n",
    "    # Set the coefficients (betas)\n",
    "    true_beta_A = 2\n",
    "    true_beta_B = 3\n",
    "    true_beta_C = 6  # Update true_beta_C to be 6\n",
    "\n",
    "    # Initialize lists to store generated data\n",
    "    X = []\n",
    "    T = []\n",
    "    Y = []\n",
    "\n",
    "    # Perform the simulations\n",
    "    for _ in range(num_simulations):\n",
    "        # Generate random binary variables A (treatment) and B (control)\n",
    "        A = np.random.randint(0, 2)\n",
    "        B = 1 - A  # B is the control group\n",
    "\n",
    "        # Generate a time variable to represent before and after periods\n",
    "        time = np.random.randint(0, 2)\n",
    "\n",
    "        # Interaction term of treatment and time\n",
    "        C = A * time\n",
    "\n",
    "        # Generate random control variables\n",
    "        controls = np.random.normal(0, 1, num_covariates)\n",
    "\n",
    "        mean_error = 0  # Mean of the error term\n",
    "        std_error = noise_std  # Standard deviation of the error term\n",
    "        error = np.random.normal(mean_error, std_error)\n",
    "\n",
    "        # Generate normally distributed outcome variable (wage)\n",
    "        mean_wage = 10  # Mean wage\n",
    "        wage = (\n",
    "            mean_wage\n",
    "            + true_beta_A * A\n",
    "            + true_beta_B * B\n",
    "            + true_beta_C * C  # Treatment effect\n",
    "            + np.sum(controls)\n",
    "            + error\n",
    "        )\n",
    "\n",
    "        # Store the generated data\n",
    "        X.append([A, B, C, *controls.tolist()])\n",
    "        T.append(time)\n",
    "        Y.append(wage)\n",
    "\n",
    "    return np.array(X), np.array(T), np.array(Y)\n",
    "\n",
    "\n",
    "# Generating the fake data with noise and more covariates\n",
    "X, T, Y = generate_data(\n",
    "    10000,\n",
    "    noise_std=10,\n",
    "    num_covariates=20,\n",
    ")  # Increase num_covariates to 20\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_C, color=\"r\", linestyle=\"--\", label=r\"$\\tau~_{ real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_A, color=\"r\", linestyle=\"--\", label=r\"$\\mu_{0~real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from causal_nets import causal_net_estimate\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set a seed value for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def generate_data(num_simulations, noise_std=10, num_covariates=10, num_periods=2):\n",
    "    # Set the coefficients (betas)\n",
    "    true_beta_A = 2\n",
    "    true_beta_B = 3\n",
    "    true_beta_C = 6  # Update true_beta_C to be 6\n",
    "\n",
    "    # Initialize lists to store generated data\n",
    "    X = []\n",
    "    T = []\n",
    "    Y = []\n",
    "\n",
    "    # Perform the simulations\n",
    "    for _ in range(num_simulations):\n",
    "        # Generate random binary variables A (treatment) and B (control)\n",
    "        A = np.random.randint(0, 2)\n",
    "        B = 1 - A  # B is the control group\n",
    "\n",
    "        # Generate random time periods\n",
    "        time_periods = np.random.randint(0, num_periods)\n",
    "\n",
    "        # Generate interaction terms of treatment and time periods\n",
    "        C = A * time_periods\n",
    "\n",
    "        # Generate random control variables\n",
    "        controls = np.random.normal(0, 1, num_covariates)\n",
    "\n",
    "        mean_error = 0  # Mean of the error term\n",
    "        std_error = noise_std  # Standard deviation of the error term\n",
    "        error = np.random.normal(mean_error, std_error)\n",
    "\n",
    "        # Generate normally distributed outcome variable (wage)\n",
    "        mean_wage = 10  # Mean wage\n",
    "        wage = (\n",
    "            mean_wage\n",
    "            + true_beta_A * A\n",
    "            + true_beta_B * B\n",
    "            + true_beta_C * C  # Treatment effect\n",
    "            + np.sum(controls)\n",
    "            + error\n",
    "        )\n",
    "\n",
    "        # Store the generated data\n",
    "        X.append([A, B, C, *controls.tolist()])\n",
    "        T.append(time_periods)\n",
    "        Y.append(wage)\n",
    "\n",
    "    return np.array(X), np.array(T), np.array(Y)\n",
    "\n",
    "\n",
    "# Generating the fake data with noise and more covariates\n",
    "X, T, Y = generate_data(\n",
    "    10000,\n",
    "    noise_std=10,\n",
    "    num_covariates=20,\n",
    ")  # Increase num_covariates to 20\n",
    "\n",
    "# Creating training and validation dataset\n",
    "X_train, X_valid, T_train, T_valid, Y_train, Y_valid = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Getting causal estimates\n",
    "(\n",
    "    tau_pred,\n",
    "    mu0_pred,\n",
    "    prob_t_pred,\n",
    "    psi_0,\n",
    "    psi_1,\n",
    "    history,\n",
    "    history_ps,\n",
    ") = causal_net_estimate(\n",
    "    [X_train, T_train, Y_train],\n",
    "    [X_valid, T_valid, Y_valid],\n",
    "    [X, T, Y],\n",
    "    [60, 30],\n",
    "    dropout_rates=None,\n",
    "    batch_size=None,\n",
    "    alpha=0.0,\n",
    "    r_par=0.2,\n",
    "    optimizer=\"Adam\",\n",
    "    learning_rate=0.0009,\n",
    "    max_epochs_without_change=30,\n",
    "    max_nepochs=5000,\n",
    "    seed=None,\n",
    "    estimate_ps=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.clf()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(tau_pred, alpha=0.6, label=r\"$\\tau~_{pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_C, color=\"r\", linestyle=\"--\", label=r\"$\\tau~_{ real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE(Conditional average treatment effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mu0_pred, alpha=0.7, label=r\"$\\mu_{0~pred}$\", density=True)\n",
    "plt.axvline(x=true_beta_A, color=\"r\", linestyle=\"--\", label=r\"$\\mu_{0~real}$\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average treatment effect\n",
    "ate = np.mean(psi_1 - psi_0)\n",
    "\n",
    "# Calculate the 95% confidence interval for average treatment effect\n",
    "CI_lowerbound = ate - norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))\n",
    "CI_upperbound = ate + norm.ppf(0.975) * np.std(psi_1 - psi_0) / np.sqrt(len(psi_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting estimated coefficient vs true coefficients\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.clf()\n",
    "\n",
    "# Plotting CATE for each time period\n",
    "plt.subplot(1, 3, 1)\n",
    "for i in range(len(history)):\n",
    "    plt.hist(\n",
    "        history[i][\"tau_pred\"],\n",
    "        alpha=0.6,\n",
    "        label=f\"Time Period {i+1}\",\n",
    "        density=True,\n",
    "    )\n",
    "plt.axvline(\n",
    "    x=true_beta_C,\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=r\"$\\tau_{real}$\",\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"CATE (Conditional Average Treatment Effect)\")\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "# Plotting mu0 for each time period\n",
    "plt.subplot(1, 3, 2)\n",
    "for i in range(len(history)):\n",
    "    plt.hist(\n",
    "        history[i][\"mu0_pred\"],\n",
    "        alpha=0.7,\n",
    "        label=f\"Time Period {i+1}\",\n",
    "        density=True,\n",
    "    )\n",
    "plt.axvline(\n",
    "    x=true_beta_A,\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=r\"$\\mu_{0~real}$\",\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(r\"$\\mu_0(x)$\")\n",
    "plt.xlabel(r\"$\\mu_0$\", fontsize=14)\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "# Calculate and plot the average treatment effect for each time period\n",
    "ate_periods = []\n",
    "for i in range(len(history)):\n",
    "    ate = np.mean(history[i][\"psi_1\"] - history[i][\"psi_0\"])\n",
    "    ate_periods.append(ate)\n",
    "    CI_lowerbound = ate - norm.ppf(0.975) * np.std(\n",
    "        history[i][\"psi_1\"] - history[i][\"psi_0\"],\n",
    "    ) / np.sqrt(len(history[i][\"psi_0\"]))\n",
    "    CI_upperbound = ate + norm.ppf(0.975) * np.std(\n",
    "        history[i][\"psi_1\"] - history[i][\"psi_0\"],\n",
    "    ) / np.sqrt(len(history[i][\"psi_0\"]))\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.errorbar(\n",
    "        [i + 1],\n",
    "        ate,\n",
    "        yerr=[[ate - CI_lowerbound], [CI_upperbound - ate]],\n",
    "        fmt=\"o\",\n",
    "        label=f\"Time Period {i+1}\",\n",
    "    )\n",
    "\n",
    "plt.axhline(y=np.mean(ate_periods), color=\"r\", linestyle=\"--\", label=\"Overall ATE\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Average Treatment Effect\")\n",
    "plt.xlabel(\"Time Period\", fontsize=14)\n",
    "plt.ylabel(\"ATE\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
