{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main model classic double robust DiD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from doubleml import DoubleMLData, DoubleMLDID\n",
    "from doubleml.datasets import make_did_SZ2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "ml_g = LinearRegression()  # as in the paper, estimators not needed\n",
    "ml_m = LogisticRegression()  # as in the paper, estimators not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 1000\n",
    "n_rep = 200\n",
    "ATTE = 0.0\n",
    "\n",
    "ATTE_estimates = np.full((n_rep), np.nan)\n",
    "coverage = np.full((n_rep), np.nan)\n",
    "ci_length = np.full((n_rep), np.nan)\n",
    "asymptotic_variance = np.full(n_rep, np.nan)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "for i_rep in range(n_rep):\n",
    "    if (i_rep % int(n_rep / 10)) == 0:\n",
    "        print(f\"Iteration: {i_rep}/{n_rep}\")\n",
    "    dml_data = make_did_SZ2020(n_obs=n_obs, dgp_type=1, cross_sectional_data=False)\n",
    "\n",
    "    dml_did = DoubleMLDID(dml_data, ml_g=ml_g, ml_m=ml_m, n_folds=5)\n",
    "    dml_did.fit()\n",
    "\n",
    "    ATTE_estimates[i_rep] = dml_did.coef.squeeze()\n",
    "    confint = dml_did.confint(level=0.95)\n",
    "    coverage[i_rep] = (confint[\"2.5 %\"].iloc[0] <= ATTE) & (\n",
    "        confint[\"97.5 %\"].iloc[0] >= ATTE\n",
    "    )\n",
    "    ci_length[i_rep] = confint[\"97.5 %\"].iloc[0] - confint[\"2.5 %\"].iloc[0]\n",
    "\n",
    "    summary_df = dml_did.summary\n",
    "    std_err = summary_df.loc[\"d\", \"std err\"]\n",
    "    asymptotic_variance[i_rep] = std_err**2\n",
    "\n",
    "# Calculate metrics\n",
    "avg_bias = np.mean(ATTE_estimates - ATTE)\n",
    "med_bias = np.median(ATTE_estimates - ATTE)\n",
    "rmse = np.sqrt(np.mean((ATTE_estimates - ATTE) ** 2))\n",
    "avg_asymptotic_variance = np.mean(asymptotic_variance)\n",
    "coverage_probability = np.mean(coverage)\n",
    "avg_ci_length = np.mean(ci_length)\n",
    "\n",
    "# Print results\n",
    "print(f\"Av. Bias: {avg_bias}\")\n",
    "print(f\"Med. Bias: {med_bias}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Asy. V: {avg_asymptotic_variance}\")\n",
    "print(f\"Cover: {coverage_probability}\")\n",
    "print(f\"CIL: {avg_ci_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWFE Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_obs = 1000\n",
    "n_rep = 200\n",
    "ATTE = 0.0  # Adjust this to reflect the true treatment effect\n",
    "\n",
    "# Storage for estimates\n",
    "ATTE_estimates = np.full(n_rep, np.nan)\n",
    "coverage = np.full(n_rep, np.nan)\n",
    "ci_length = np.full(n_rep, np.nan)\n",
    "asymptotic_variance = np.full(n_rep, np.nan)\n",
    "\n",
    "biases = []\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    if i_rep % int(n_rep / 10) == 0:\n",
    "        print(f\"Iteration: {i_rep}/{n_rep}\")\n",
    "\n",
    "    # Generate data\n",
    "    x, y, d = make_did_SZ2020(\n",
    "        n_obs=n_obs,\n",
    "        dgp_type=4,\n",
    "        cross_sectional_data=False,\n",
    "        return_type=\"array\",\n",
    "    )\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(x, columns=[f\"X{i+1}\" for i in range(x.shape[1])])\n",
    "    df[\"y\"] = y\n",
    "    df[\"d\"] = d\n",
    "    df[\"time\"] = np.random.randint(\n",
    "        2,\n",
    "        size=len(df),\n",
    "    )  # Example time indicator (replace with your time indicator)\n",
    "\n",
    "    # Fit TWFE model using statsmodels\n",
    "    formula = \"y ~ d + time + d:time + X1:time + X2:time + X3:time + X4:time \"\n",
    "    model = smf.ols(formula=formula, data=df).fit()\n",
    "\n",
    "    # Extract the treatment effect estimate (coefficient of the treatment variable)\n",
    "    tau_fe = model.params[\"d:time\"]\n",
    "    ATTE_estimates[i_rep] = tau_fe\n",
    "\n",
    "    # Calculate and store the bias\n",
    "    bias = tau_fe - ATTE\n",
    "    biases.append(bias)\n",
    "\n",
    "    # Confidence intervals\n",
    "    ci = model.conf_int().loc[\"d:time\"]\n",
    "    ci_length[i_rep] = ci[1] - ci[0]\n",
    "    coverage[i_rep] = ci[0] <= ATTE <= ci[1]\n",
    "    asymptotic_variance[i_rep] = model.bse[\"d:time\"] ** 2\n",
    "\n",
    "# Calculate metrics\n",
    "avg_bias = np.mean(biases)\n",
    "med_bias = np.median(biases)\n",
    "rmse = np.sqrt(np.mean(np.square(biases)))\n",
    "mean_coverage = np.mean(coverage)\n",
    "mean_ci_length = np.mean(ci_length)\n",
    "mean_asymptotic_variance = np.mean(asymptotic_variance)\n",
    "# Print results\n",
    "print(f\"Av. Bias: {avg_bias}\")\n",
    "print(f\"Med. Bias: {med_bias}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Coverage:{mean_coverage}\")\n",
    "print(f\"mean_ci_length:{mean_ci_length}\")\n",
    "print(f\"mean_asymptotic_variance:{mean_asymptotic_variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning with a few runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from doubleml import DoubleMLData, DoubleMLDID\n",
    "from doubleml.datasets import make_did_SZ2020\n",
    "from lightgbm import LGBMRegressor\n",
    "from scikeras.wrappers import KerasClassifier  # pip install scikeras\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "n_reps = 10  # change that accordingly\n",
    "n_obs = 1000\n",
    "\n",
    "# Function to create Keras model\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=x.shape[1], activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))  # Assuming binary classification\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize arrays to store statistics\n",
    "biases = np.zeros(n_reps)\n",
    "variances = np.zeros(n_reps)\n",
    "rmse_list = np.zeros(n_reps)\n",
    "coverage_probs = np.zeros(n_reps)\n",
    "ci_lengths = np.zeros(n_reps)\n",
    "\n",
    "for i_rep in range(n_reps):\n",
    "    x, y, d = make_did_SZ2020(\n",
    "        n_obs=n_obs,\n",
    "        dgp_type=4,\n",
    "        cross_sectional_data=False,\n",
    "        return_type=\"array\",\n",
    "    )\n",
    "    dml_data = DoubleMLData.from_arrays(x=x, y=y, d=d)\n",
    "\n",
    "    # Wrap the Keras model with KerasClassifier\n",
    "    keras_classifier = KerasClassifier(\n",
    "        build_fn=create_model,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Use StandardScaler to normalize data and then use the Keras classifier in a pipeline\n",
    "    ml_m = Pipeline([(\"scaler\", StandardScaler()), (\"nn\", keras_classifier)])\n",
    "\n",
    "    # Use LGBMRegressor for regression\n",
    "    n_estimators = 30\n",
    "    ml_g = LGBMRegressor(n_estimators=n_estimators)\n",
    "\n",
    "    dml_plr = DoubleMLDID(dml_data, ml_g, ml_m)\n",
    "    dml_plr.fit()\n",
    "\n",
    "    ATTE_estimates[i_rep] = dml_plr.coef.squeeze()\n",
    "    confint = dml_plr.confint(level=0.95)\n",
    "    coverage[i_rep] = (confint[\"2.5 %\"].iloc[0] <= ATTE) & (\n",
    "        confint[\"97.5 %\"].iloc[0] >= ATTE\n",
    "    )\n",
    "    ci_length[i_rep] = confint[\"97.5 %\"].iloc[0] - confint[\"2.5 %\"].iloc[0]\n",
    "    # Extract standard error from the summary\n",
    "    summary_df = dml_plr.summary\n",
    "    std_err = summary_df.loc[\"d\", \"std err\"]\n",
    "    asymptotic_variance[i_rep] = std_err**2\n",
    "\n",
    "# Calculate metrics\n",
    "avg_bias = np.mean(ATTE_estimates - ATTE)\n",
    "med_bias = np.median(ATTE_estimates - ATTE)\n",
    "rmse = np.sqrt(np.mean((ATTE_estimates - ATTE) ** 2))\n",
    "avg_asymptotic_variance = np.mean(asymptotic_variance)\n",
    "coverage_probability = np.mean(coverage)\n",
    "avg_ci_length = np.mean(ci_length)\n",
    "\n",
    "# Print results\n",
    "print(f\"Av. Bias: {avg_bias}\")\n",
    "print(f\"Med. Bias: {med_bias}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Asy. V: {avg_asymptotic_variance}\")\n",
    "print(f\"Cover: {coverage_probability}\")\n",
    "print(f\"CIL: {avg_ci_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulaization Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df_pa = pd.DataFrame(ATTE_estimates, columns=[\"Estimate\"])\n",
    "g = sns.kdeplot(df_pa, fill=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
